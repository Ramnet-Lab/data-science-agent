{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d468608-de97-433e-b271-0762825fc2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source ag/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d22a73c-3c3a-4bf9-b51f-b35069a8a964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import Tool, StructuredTool\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas_gbq\n",
    "import os\n",
    "import tempfile\n",
    "import fitz  # PyMuPDF\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.parse import urlparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "# --- Environment Setup ---\n",
    "OPENAI_API_KEY = \"your_openai_api_key\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "# --- Pydantic Models for Tool Input ---\n",
    "class ReadFileRequest(BaseModel):\n",
    "    file_path: str = Field(description=\"The path to the data file.\")\n",
    "\n",
    "class GenerateAnalysisCodeRequest(BaseModel):\n",
    "    file_path: str = Field(description=\"The path to the data file.\")\n",
    "    analysis_objective: str = Field(description=\"The objective of the request (e.g., answer).\")\n",
    "\n",
    "class ExecuteCodeRequest(BaseModel):\n",
    "    code: str = Field(description=\"The Python code to execute.\")\n",
    "\n",
    "class AnalyzeResultsRequest(BaseModel):\n",
    "    code_output: str = Field(description=\"The output from executing the code.\")\n",
    "    plot_files: List[str] = Field(description=\"List of paths to the generated useful data.\")\n",
    "\n",
    "class CreateReportRequest(BaseModel):\n",
    "    analysis: str = Field(description=\"The analysis of the results.\")\n",
    "    plot_files: List[str] = Field(description=\"List of paths to the generated data files.\")\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def read_data_file(file_path: str) -> str:\n",
    "    \"\"\"Reads a data file and returns a description.\"\"\"\n",
    "    try:\n",
    "        if file_path.endswith(('.csv')):\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif file_path.endswith(('.xlsx', '.xls')):\n",
    "            df = pd.read_excel(file_path)\n",
    "        else:\n",
    "            return f\"Error: Unsupported file format: {file_path}\"\n",
    "        return f\"Successfully read data from {file_path}. DataFrame info:\\n{df.info()}\\n\\nFirst 5 rows:\\n{df.head().to_string()}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {e}\"\n",
    "\n",
    "def execute_python_code(code: str) -> tuple[str, List[str]]:\n",
    "    \"\"\"Executes Python code and captures output and any data file paths.\"\"\"\n",
    "    temp_file = None\n",
    "    plot_files = []\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as tmp_file:\n",
    "            tmp_file.write(code)\n",
    "            temp_file = tmp_file.name\n",
    "\n",
    "        import subprocess\n",
    "        process = subprocess.Popen(['python', temp_file], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        stdout, stderr = process.communicate()\n",
    "\n",
    "        if stderr:\n",
    "            return f\"Error during code execution:\\n{stderr}\", []\n",
    "        else:\n",
    "            # Collect generated plot files (basic heuristic)\n",
    "            for filename in os.listdir():\n",
    "                if filename.startswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    plot_files.append(filename)\n",
    "            return f\"Code executed successfully. Output:\\n{stdout}\", plot_files\n",
    "    except Exception as e:\n",
    "        return f\"Error executing code: {e}\", []\n",
    "    finally:\n",
    "        if temp_file and os.path.exists(temp_file):\n",
    "            os.remove(temp_file)\n",
    "\n",
    "# --- Tools ---\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"read_data_file\",\n",
    "        func=read_data_file,\n",
    "        description=\"Useful for reading a data file (CSV or Excel) and getting information about its columns and data types. Input should be the file path.\",\n",
    "        args_schema=ReadFileRequest\n",
    "    ),\n",
    "    StructuredTool(\n",
    "        name=\"generate_data_analysis_code\",\n",
    "        func=lambda file_path, analysis_objective: ChatOpenAI(model=model).predict(\n",
    "            f\"Generate Python code for {analysis_objective} on the data in '{file_path}'. Include saving relevant plots to files in a directory named 'eda_plots'.\"\n",
    "        ),\n",
    "        description=\"Generates Python code for data analysis ops based on the file and the objective. Input should be the file path and the objective (e.g., 'data analysis').\",\n",
    "        args_schema=GenerateAnalysisCodeRequest\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"execute_python_code\",\n",
    "        func=execute_python_code,\n",
    "        description=\"Executes Python code and returns the output and paths to any generated data files. Input is the Python code.\",\n",
    "        args_schema=ExecuteCodeRequest\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# --- Initialize Agent ---\n",
    "llm = ChatOpenAI(model=model, max_tokens=8000)\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, memory_key=\"chat_history\")\n",
    "\n",
    "# Construct the prompt with HumanMessagePromptTemplate\n",
    "prompt_messages = [\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "You are an expert data analyst and Python programmer specializing in high-performance computing. Your task is to:\n",
    "- Generate Python code to maximize hardware capabilites, leveraging all available CPU cores, GPU acceleration (if applicable), and parallel processing for large dataset handling.\n",
    "- Incorporate tools such as threading, and hardware-accelerated libraries like `NumPy`, `Pandas`, or `Dask` to ensure the code scales efficiently for large datasets.\n",
    "- Leverage multiprocessing and gpu(concurrent.futures, multiprocessing, scikit-learn, pyspark, numpy arrays)  libraries to speed up workflow.\n",
    "\n",
    "Available tools:\n",
    "{tool_descriptions}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Input: the input to the tool\n",
    "Thought: I need to use a tool to help me answer the question.\n",
    "Action: the name of the tool to use.\n",
    "Action Input: the input to the tool.\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer.\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Your goal is to ensure the generated code is optimized for large-scale data processing and hardware acceleration wherever applicable.\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\")\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(prompt_messages)\n",
    "\n",
    "# Initialize the agent\n",
    "agent_executor = initialize_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,  # Choose an appropriate agent type\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=\"Check your output format and try again.\",\n",
    "    max_iterations=10000\n",
    ")\n",
    "\n",
    "# --- Example Usage ---\n",
    "file_path = \"/home/jovyan/Autogen/normalized_data.csv\"  # Make sure this file exists in the same directory or provide the full path\n",
    "\n",
    "prompt_text = f\"\"\" \n",
    "Objective:\n",
    "Develop a comprehensive, end-to-end data analysis pipeline for a given dataset. The solution should load, clean, and process the data robustly (e.g., handling type conversion issues), and produce a detailed textual analysis.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "    Data Ingestion & Preprocessing:\n",
    "        Load the dataset from a CSV (or similar structured) file.\n",
    "        Identify columns that may contain JSON-like strings and automatically convert these into structured (e.g., dictionary) objects. Ensure that non-standard formats (such as single-quoted JSON) are handled gracefully using appropriate parsing methods (e.g., ast.literal_eval or json.loads with preprocessing).\n",
    "        Automatically detect and resolve common data type issues (for example, converting numeric fields safely using pd.to_numeric with error handling, parsing datetime fields, etc.), so that errors such as \"string to float\" conversion issues are avoided.\n",
    "    Performance & Scalability:\n",
    "        Utilize threading to distribute the load across all available CPU cores (24 physical, 48 logical with Hyper-Threading) where it can effectively speed up data processing tasks.\n",
    "        Where applicable and beneficial (for example, heavy computations or large-scale data processing), leverage GPU acceleration (e.g., an RTX 2080 with 8GB VRAM) to improve performance.\n",
    "    Deliverables:\n",
    "        Provide complete, well-documented code that performs all of the above tasks.\n",
    "        The output should include both the generated visualizations (charts, graphs, etc.) and a detailed textual analysis explaining the reasoning and insights derived from the data.\n",
    "\n",
    "Task: Itendify any hidden connections visulize the data in time domian plots ect.\n",
    "\n",
    "Hardware Available:\n",
    "\n",
    "    CPU: 24 cores (48 logical cores with Hyper-Threading)\n",
    "    GPU: RTX 2080 with 8GB VRAM\n",
    "    \n",
    "\n",
    "Additional Notes:\n",
    "\n",
    "    The code must be written to be resilient against common data issues, such as inconsistent formatting or unexpected data types.\n",
    "    Ensure that any potential errors (e.g., conversion issues) are handled gracefully.\n",
    "    The solution should be modular enough to be adapted easily to different datasets with similar challenges.\n",
    "    any plots generated use tight_layout() to generate dynamic sizes plots to fit your labels\n",
    "    use spaCy for word similariy and sematic search when interacting or searching for message objects. \n",
    "\n",
    "The path of the dataset is '{file_path}'\"\"\"\n",
    "\n",
    "response = agent_executor.run(prompt_text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761015c5-f29a-4d40-83de-8acc295b35c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
